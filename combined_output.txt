=== File: .env ===
#UPLOAD_FOLDER = os.path.join(os.getcwd(), 'uploads')
UPLOAD_FOLDER=uploads
REPORT_FOLDER=reports



=== File: app.py ===
from flask import Flask, jsonify, request, render_template
import pandas as pd
import numpy as np
import os 
from upload import upload_bp
from validate import validate_bp

app = Flask(__name__)
# Load folders from .env or set defaults
UPLOAD_FOLDER = os.getenv('UPLOAD_FOLDER', 'uploads')
REPORT_FOLDER = os.getenv('REPORT_FOLDER', 'reports')
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(REPORT_FOLDER, exist_ok=True)

app.register_blueprint(upload_bp)
app.register_blueprint(validate_bp)

@app.route('/')
def Index():
    return render_template('index.html')



if __name__ == '__main__':
    app.run(debug=True)



=== File: requirements.txt ===
Flask==3.0.3
pandas==2.2.2
numpy==1.26.4
great-expectations==1.3.5
matplotlib==3.9.2
seaborn==0.13.2
openpyxl==3.1.5   # for Excel file support
xlrd==2.0.1       # for older Excel formats



=== File: upload.py ===
import os
from flask import Blueprint, request, jsonify

upload_bp = Blueprint('upload_bp', __name__)

UPLOAD_FOLDER = os.path.join(os.getcwd(), 'uploads')
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

@upload_bp.route('/upload', methods=['POST'])
def upload_file():
    if 'dataset' not in request.files:
        return jsonify({"status": "error", "message": "No file part"}), 400

    file = request.files['dataset']
    if file.filename == '':
        return jsonify({"status": "error", "message": "No selected file"}), 400

    filepath = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(filepath)

    return jsonify({"status": "success", "message": f"File saved to {filepath}"})



=== File: validate.py ===
from flask import Flask, render_template, request, redirect, url_for, send_file, flash, Blueprint
import os
from dotenv import load_dotenv
from validator import validate_dataset_with_expectations
#app = Flask(__name__)
validate_bp = Blueprint('validate_bp', __name__)

@validate_bp.route('/validate/<filename>')
def validate_file(filename):
    filepath = os.path.join(os.getenv('UPLOAD_FOLDER'), filename)

    try:
        result = validate_dataset_with_expectations(filepath, os.getenv('REPORT_FOLDER'))
        report_path = result["report_path"]
        return send_file(report_path, mimetype='text/html')
    except Exception as e:
        return f"<h3>Error during validation:</h3><pre>{e}</pre>"



=== File: validator.py ===
import os
import pandas as pd
import great_expectations as ge

def validate_dataset_with_expectations(filepath, report_folder):
    """
    Runs a comprehensive set of Great Expectations checks on a dataset
    and generates a Data Docs HTML report.
    """
    # Load dataset based on extension
    if filepath.endswith(".csv"):
        df = pd.read_csv(filepath)
    elif filepath.endswith((".xlsx", ".xls")):
        df = pd.read_excel(filepath)
    elif filepath.endswith(".json"):
        df = pd.read_json(filepath)
    else:
        raise ValueError("Unsupported file format")

    # Wrap with Great Expectations
    gdf = ge.from_pandas(df)

    # --- Global Table-Level Expectations ---
    gdf.expect_table_row_count_to_be_greater_than(0)
    gdf.expect_table_columns_to_match_set(df.columns.tolist())

    # --- Column-wise Expectations ---
    for col in df.columns:
        # Null / completeness checks
        gdf.expect_column_values_to_not_be_null(col)

        # Data type based checks
        if pd.api.types.is_numeric_dtype(df[col]):
            gdf.expect_column_values_to_be_in_type_list(col, ["integer", "float", "number"])
            gdf.expect_column_mean_to_be_between(col, df[col].min(), df[col].max())
            gdf.expect_column_median_to_be_between(col, df[col].min(), df[col].max())
            gdf.expect_column_values_to_be_between(col, min_value=df[col].min(), max_value=df[col].max())

            # Optional: unique checks for ID-like numeric fields
            if df[col].nunique() == len(df):
                gdf.expect_column_values_to_be_unique(col)

        elif pd.api.types.is_string_dtype(df[col]):
            gdf.expect_column_values_to_be_in_type_list(col, ["object", "string"])
            gdf.expect_column_value_lengths_to_be_between(col, 0, 255)

            # Optional: uniqueness for likely identifiers
            if df[col].nunique() == len(df):
                gdf.expect_column_values_to_be_unique(col)

        elif pd.api.types.is_datetime64_any_dtype(df[col]):
            gdf.expect_column_values_to_be_in_type_list(col, ["datetime"])
            gdf.expect_column_values_to_not_be_null(col)

        # Check for unexpected values (auto)
        if df[col].nunique() < 30:  # categorical-like
            allowed_values = df[col].dropna().unique().tolist()
            gdf.expect_column_values_to_be_in_set(col, allowed_values)

    # --- Run Validation ---
    validation_result = gdf.validate()

    # --- Generate Data Docs ---
    context = ge.get_context()
    os.makedirs(report_folder, exist_ok=True)

    # We manually save a simple HTML report for this dataset
    filename = os.path.basename(filepath)
    report_path = os.path.join(report_folder, f"{filename}_report.html")

    # Great Expectations' built-in docs builder works if context is configured,
    # but for ad-hoc use we can save the validation result manually:
    context.build_data_docs()
    # Alternatively:
    # from great_expectations.render.renderer.validation_results_page_renderer import ValidationResultsPageRenderer
    # from great_expectations.render.view import DefaultJinjaPageView
    # renderer = ValidationResultsPageRenderer()
    # rendered_document_content = renderer.render(validation_result)
    # view = DefaultJinjaPageView()
    # rendered_html = view.render(rendered_document_content)
    # with open(report_path, "w", encoding="utf-8") as f:
    #     f.write(rendered_html)

    return {
        "result": validation_result,
        "report_path": report_path
    }



=== File: .env ===
#UPLOAD_FOLDER = os.path.join(os.getcwd(), 'uploads')
UPLOAD_FOLDER=uploads
REPORT_FOLDER=reports



=== File: app.py ===
from flask import Flask, render_template
import os
from dotenv import load_dotenv
from upload import upload_bp
from validate import validate_bp

# Load environment variables
load_dotenv()

app = Flask(__name__)

# Load folder paths
UPLOAD_FOLDER = os.getenv('UPLOAD_FOLDER', 'uploads')
REPORT_FOLDER = os.getenv('REPORT_FOLDER', 'reports')

# Ensure directories exist
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(REPORT_FOLDER, exist_ok=True)

# Register blueprints
app.register_blueprint(upload_bp)
app.register_blueprint(validate_bp)

@app.route('/')
def index():
    return render_template('index.html')

if __name__ == '__main__':
    app.run(debug=True)



=== File: combined_output.txt ===
=== File: .env ===
#UPLOAD_FOLDER = os.path.join(os.getcwd(), 'uploads')
UPLOAD_FOLDER=uploads
REPORT_FOLDER=reports



=== File: app.py ===
from flask import Flask, jsonify, request, render_template
import pandas as pd
import numpy as np
import os 
from upload import upload_bp
from validate import validate_bp

app = Flask(__name__)
# Load folders from .env or set defaults
UPLOAD_FOLDER = os.getenv('UPLOAD_FOLDER', 'uploads')
REPORT_FOLDER = os.getenv('REPORT_FOLDER', 'reports')
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(REPORT_FOLDER, exist_ok=True)

app.register_blueprint(upload_bp)
app.register_blueprint(validate_bp)

@app.route('/')
def Index():
    return render_template('index.html')



if __name__ == '__main__':
    app.run(debug=True)



=== File: requirements.txt ===
Flask==3.0.3
pandas==2.2.2
numpy==1.26.4
great-expectations==1.3.5
matplotlib==3.9.2
seaborn==0.13.2
openpyxl==3.1.5   # for Excel file support
xlrd==2.0.1       # for older Excel formats



=== File: upload.py ===
import os
from flask import Blueprint, request, jsonify

upload_bp = Blueprint('upload_bp', __name__)

UPLOAD_FOLDER = os.path.join(os.getcwd(), 'uploads')
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

@upload_bp.route('/upload', methods=['POST'])
def upload_file():
    if 'dataset' not in request.files:
        return jsonify({"status": "error", "message": "No file part"}), 400

    file = request.files['dataset']
    if file.filename == '':
        return jsonify({"status": "error", "message": "No selected file"}), 400

    filepath = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(filepath)

    return jsonify({"status": "success", "message": f"File saved to {filepath}"})



=== File: validate.py ===
from flask import Flask, render_template, request, redirect, url_for, send_file, flash, Blueprint
import os
from dotenv import load_dotenv
from validator import validate_dataset_with_expectations
#app = Flask(__name__)
validate_bp = Blueprint('validate_bp', __name__)

@validate_bp.route('/validate/<filename>')
def validate_file(filename):
    filepath = os.path.join(os.getenv('UPLOAD_FOLDER'), filename)

    try:
        result = validate_dataset_with_expectations(filepath, os.getenv('REPORT_FOLDER'))
        report_path = result["report_path"]
        return send_file(report_path, mimetype='text/html')
    except Exception as e:
        return f"<h3>Error during validation:</h3><pre>{e}</pre>"



=== File: validator.py ===
import os
import pandas as pd
import great_expectations as ge

def validate_dataset_with_expectations(filepath, report_folder):
    """
    Runs a comprehensive set of Great Expectations checks on a dataset
    and generates a Data Docs HTML report.
    """
    # Load dataset based on extension
    if filepath.endswith(".csv"):
        df = pd.read_csv(filepath)
    elif filepath.endswith((".xlsx", ".xls")):
        df = pd.read_excel(filepath)
    elif filepath.endswith(".json"):
        df = pd.read_json(filepath)
    else:
        raise ValueError("Unsupported file format")

    # Wrap with Great Expectations
    gdf = ge.from_pandas(df)

    # --- Global Table-Level Expectations ---
    gdf.expect_table_row_count_to_be_greater_than(0)
    gdf.expect_table_columns_to_match_set(df.columns.tolist())

    # --- Column-wise Expectations ---
    for col in df.columns:
        # Null / completeness checks
        gdf.expect_column_values_to_not_be_null(col)

        # Data type based checks
        if pd.api.types.is_numeric_dtype(df[col]):
            gdf.expect_column_values_to_be_in_type_list(col, ["integer", "float", "number"])
            gdf.expect_column_mean_to_be_between(col, df[col].min(), df[col].max())
            gdf.expect_column_median_to_be_between(col, df[col].min(), df[col].max())
            gdf.expect_column_values_to_be_between(col, min_value=df[col].min(), max_value=df[col].max())

            # Optional: unique checks for ID-like numeric fields
            if df[col].nunique() == len(df):
                gdf.expect_column_values_to_be_unique(col)

        elif pd.api.types.is_string_dtype(df[col]):
            gdf.expect_column_values_to_be_in_type_list(col, ["object", "string"])
            gdf.expect_column_value_lengths_to_be_between(col, 0, 255)

            # Optional: uniqueness for likely identifiers
            if df[col].nunique() == len(df):
                gdf.expect_column_values_to_be_unique(col)

        elif pd.api.types.is_datetime64_any_dtype(df[col]):
            gdf.expect_column_values_to_be_in_type_list(col, ["datetime"])
            gdf.expect_column_values_to_not_be_null(col)

        # Check for unexpected values (auto)
        if df[col].nunique() < 30:  # categorical-like
            allowed_values = df[col].dropna().unique().tolist()
            gdf.expect_column_values_to_be_in_set(col, allowed_values)

    # --- Run Validation ---
    validation_result = gdf.validate()

    # --- Generate Data Docs ---
    context = ge.get_context()
    os.makedirs(report_folder, exist_ok=True)

    # We manually save a simple HTML report for this dataset
    filename = os.path.basename(filepath)
    report_path = os.path.join(report_folder, f"{filename}_report.html")

    # Great Expectations' built-in docs builder works if context is configured,
    # but for ad-hoc use we can save the validation result manually:
    context.build_data_docs()
    # Alternatively:
    # from great_expectations.render.renderer.validation_results_page_renderer import ValidationResultsPageRenderer
    # from great_expectations.render.view import DefaultJinjaPageView
    # renderer = ValidationResultsPageRenderer()
    # rendered_document_content = renderer.render(validation_result)
    # view = DefaultJinjaPageView()
    # rendered_html = view.render(rendered_document_content)
    # with open(report_path, "w", encoding="utf-8") as f:
    #     f.write(rendered_html)

    return {
        "result": validation_result,
        "report_path": report_path
    }



=== File: .env ===
#UPLOAD_FOLDER = os.path.join(os.getcwd(), 'uploads')
UPLOAD_FOLDER=uploads
REPORT_FOLDER=reports



=== File: app.py ===
from flask import Flask, render_template
import os
from dotenv import load_dotenv
from upload import upload_bp
from validate import validate_bp

# Load environment variables
load_dotenv()

app = Flask(__name__)

# Load folder paths
UPLOAD_FOLDER = os.getenv('UPLOAD_FOLDER', 'uploads')
REPORT_FOLDER = os.getenv('REPORT_FOLDER', 'reports')

# Ensure directories exist
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(REPORT_FOLDER, exist_ok=True)

# Register blueprints
app.register_blueprint(upload_bp)
app.register_blueprint(validate_bp)

@app.route('/')
def index():
    return render_template('index.html')

if __name__ == '__main__':
    app.run(debug=True)



=== File: combined_output.txt ===



=== File: requirements.txt ===
Flask==3.0.3
pandas==2.2.2
numpy==1.26.4
great-expectations==1.3.5
matplotlib==3.9.2
seaborn==0.13.2
openpyxl==3.1.5
xlrd==2.0.1
python-dotenv==1.0.1



=== File: upload.py ===
import os
from flask import Blueprint, request, jsonify, redirect, url_for

upload_bp = Blueprint('upload_bp', __name__)

UPLOAD_FOLDER = os.getenv('UPLOAD_FOLDER', os.path.join(os.getcwd(), 'uploads'))
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

@upload_bp.route('/upload', methods=['POST'])
def upload_file():
    if 'dataset' not in request.files:
        return jsonify({"status": "error", "message": "No file part"}), 400

    file = request.files['dataset']
    if file.filename == '':
        return jsonify({"status": "error", "message": "No selected file"}), 400

    filepath = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(filepath)

    # After upload, redirect to validation page
    return redirect(url_for('validate_bp.validate_file', filename=file.filename))



=== File: validate.py ===
from flask import Blueprint, send_file
import os
from dotenv import load_dotenv
from validator import validate_dataset_with_expectations

validate_bp = Blueprint('validate_bp', __name__)
load_dotenv()

@validate_bp.route('/validate/<filename>')
def validate_file(filename):
    upload_folder = os.getenv('UPLOAD_FOLDER', 'uploads')
    report_folder = os.getenv('REPORT_FOLDER', 'reports')

    filepath = os.path.join(upload_folder, filename)

    try:
        result = validate_dataset_with_expectations(filepath, report_folder)
        return send_file(result["report_path"], mimetype='text/html')
    except Exception as e:
        return f"<h3>Error during validation:</h3><pre>{str(e)}</pre>"



=== File: validator.py ===
import os
import pandas as pd
import great_expectations as ge
import json
from datetime import datetime

def validate_dataset_with_expectations(filepath, report_folder):
    """
    Runs Great Expectations checks on a dataset and generates a clean HTML report.
    Compatible with GE 1.3.5 (no deprecated renderer).
    """
    # Load dataset
    ext = os.path.splitext(filepath)[1].lower()
    if ext == ".csv":
        df = pd.read_csv(filepath)
    elif ext in [".xlsx", ".xls"]:
        df = pd.read_excel(filepath)
    elif ext == ".json":
        df = pd.read_json(filepath)
    else:
        raise ValueError(f"Unsupported file format: {ext}")

    # Wrap DataFrame with Great Expectations
    gdf = ge.from_pandas(df)

    # Global expectations
    gdf.expect_table_row_count_to_be_greater_than(0)
    gdf.expect_table_columns_to_match_set(df.columns.tolist())

    # Column-wise expectations
    for col in df.columns:
        gdf.expect_column_values_to_not_be_null(col)

        if pd.api.types.is_numeric_dtype(df[col]):
            gdf.expect_column_values_to_be_in_type_list(col, ["integer", "float", "number"])
            gdf.expect_column_values_to_be_between(col, df[col].min(), df[col].max())
            gdf.expect_column_mean_to_be_between(col, df[col].min(), df[col].max())
            gdf.expect_column_median_to_be_between(col, df[col].min(), df[col].max())
            if df[col].nunique() == len(df):
                gdf.expect_column_values_to_be_unique(col)

        elif pd.api.types.is_string_dtype(df[col]):
            gdf.expect_column_values_to_be_in_type_list(col, ["object", "string"])
            gdf.expect_column_value_lengths_to_be_between(col, 0, 255)
            if df[col].nunique() == len(df):
                gdf.expect_column_values_to_be_unique(col)

        elif pd.api.types.is_datetime64_any_dtype(df[col]):
            gdf.expect_column_values_to_be_in_type_list(col, ["datetime"])
            gdf.expect_column_values_to_not_be_null(col)

        if df[col].nunique() < 30:
            allowed_values = df[col].dropna().unique().tolist()
            gdf.expect_column_values_to_be_in_set(col, allowed_values)

    # Run validation
    validation_result = gdf.validate()

    # Build simple HTML report
    os.makedirs(report_folder, exist_ok=True)
    filename = os.path.basename(filepath)
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report_path = os.path.join(report_folder, f"{filename}_report.html")

    summary_html = f"""
    <html>
    <head>
        <title>Validation Report - {filename}</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; }}
            h1 {{ color: #333; }}
            table {{ border-collapse: collapse; width: 100%; margin-top: 20px; }}
            th, td {{ border: 1px solid #ccc; padding: 8px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
            .success {{ color: green; font-weight: bold; }}
            .failure {{ color: red; font-weight: bold; }}
        </style>
    </head>
    <body>
        <h1>Validation Report: {filename}</h1>
        <p><strong>Generated:</strong> {timestamp}</p>
        <p><strong>Total Expectations:</strong> {len(validation_result['results'])}</p>
    """

    # Add expectations table
    summary_html += "<table><tr><th>Expectation</th><th>Success</th><th>Details</th></tr>"
    for res in validation_result['results']:
        exp_type = res['expectation_config']['expectation_type']
        success = res['success']
        details = json.dumps(res['result'], indent=2)
        summary_html += f"<tr><td>{exp_type}</td><td>{'✅' if success else '❌'}</td><td><pre>{details}</pre></td></tr>"
    summary_html += "</table></body></html>"

    with open(report_path, "w", encoding="utf-8") as f:
        f.write(summary_html)

    return {
        "result": validation_result,
        "report_path": report_path
    }



